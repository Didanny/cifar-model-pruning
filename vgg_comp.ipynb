{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dannya1/anaconda3/envs/torch2/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_cifar_models\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import CIFAR10, CIFAR100\n",
    "from torchmetrics.classification import Accuracy\n",
    "from common import *\n",
    "from collections import OrderedDict\n",
    "# import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 0.005\n",
    "i = 0.005\n",
    "max_sparsity = 0.24\n",
    "mode = 'inf'\n",
    "model_name = 'cifar100_vgg19_bn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fe87c139bb0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_val_transforms(mean, std):\n",
    "    return T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean, std)\n",
    "    ])\n",
    "    \n",
    "# CIFAR-10\n",
    "# val_set = CIFAR10('./data', train=False, download=False, transform=get_val_transforms(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]))\n",
    "# train_set = CIFAR10('./data', train=True, download=False)\n",
    "\n",
    "# CIFAR-100\n",
    "val_set = CIFAR100('./data', train=False, download=False, transform=get_val_transforms(mean=[0.5070, 0.4865, 0.4409], std=[0.2673, 0.2564, 0.2761]))\n",
    "train_set = CIFAR100('./data', train=True, download=False)\n",
    "\n",
    "val_loader = data.DataLoader(val_set, batch_size=256, shuffle=False)\n",
    "val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311.8481636047363"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = Profile()\n",
    "with dt:\n",
    "    model = getattr(pytorch_cifar_models, model_name)(pretrained=True)\n",
    "# model.eval()\n",
    "dt.t * 1E3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (35): ReLU(inplace=True)\n",
      "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (38): ReLU(inplace=True)\n",
      "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (45): ReLU(inplace=True)\n",
      "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (48): ReLU(inplace=True)\n",
      "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (51): ReLU(inplace=True)\n",
      "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=512, out_features=100, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_total = get_num_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity=0.005\n",
      "Sparsity=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dannya1/cifar-model-pruning/common.py:513: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  torch.range(0, module.weight.shape[0] - 1).to(module.weight.device), # filter idx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity=0.015\n",
      "Sparsity=0.02\n",
      "Sparsity=0.025\n",
      "Sparsity=0.030000000000000002\n",
      "Sparsity=0.035\n",
      "Sparsity=0.04\n",
      "Sparsity=0.045\n",
      "Sparsity=0.049999999999999996\n",
      "Sparsity=0.05499999999999999\n",
      "Sparsity=0.05999999999999999\n",
      "Sparsity=0.06499999999999999\n",
      "Sparsity=0.06999999999999999\n",
      "Sparsity=0.075\n",
      "Sparsity=0.08\n",
      "Sparsity=0.085\n",
      "Sparsity=0.09000000000000001\n",
      "Sparsity=0.09500000000000001\n",
      "Sparsity=0.10000000000000002\n",
      "Sparsity=0.10500000000000002\n",
      "Sparsity=0.11000000000000003\n",
      "Sparsity=0.11500000000000003\n",
      "Sparsity=0.12000000000000004\n",
      "Sparsity=0.12500000000000003\n",
      "Sparsity=0.13000000000000003\n",
      "Sparsity=0.13500000000000004\n",
      "Sparsity=0.14000000000000004\n",
      "Sparsity=0.14500000000000005\n",
      "Sparsity=0.15000000000000005\n",
      "Sparsity=0.15500000000000005\n",
      "Sparsity=0.16000000000000006\n",
      "Sparsity=0.16500000000000006\n",
      "Sparsity=0.17000000000000007\n",
      "Sparsity=0.17500000000000007\n",
      "Sparsity=0.18000000000000008\n",
      "Sparsity=0.18500000000000008\n",
      "Sparsity=0.19000000000000009\n",
      "Sparsity=0.1950000000000001\n",
      "Sparsity=0.2000000000000001\n",
      "Sparsity=0.2050000000000001\n",
      "Sparsity=0.2100000000000001\n",
      "Sparsity=0.2150000000000001\n",
      "Sparsity=0.2200000000000001\n",
      "Sparsity=0.22500000000000012\n",
      "Sparsity=0.23000000000000012\n",
      "Sparsity=0.23500000000000013\n",
      "tensor(7186410)\n",
      "20612004\n"
     ]
    }
   ],
   "source": [
    "dependencies = get_dependency_graph(model, model_name)\n",
    "residual_dependencies = get_residual_dependency(model, model_name)\n",
    "parameters_to_prune = get_parameters_to_prune(model, model_name)\n",
    "name_to_module = get_name_to_module(model)\n",
    "\n",
    "# global_smallest_filter(parameters_to_prune, 0.2, mode)\n",
    "while i < max_sparsity:\n",
    "    print(f'Sparsity={i}')\n",
    "    global_smallest_filter(parameters_to_prune, i, mode)\n",
    "    for key in dependencies:\n",
    "        mod = name_to_module[key]\n",
    "        mod_dep = name_to_module[dependencies[key]]\n",
    "        prune_kernel2(mod, mod_dep)\n",
    "    for key in residual_dependencies:\n",
    "        mod = name_to_module[key] \n",
    "        mod_dep = name_to_module[residual_dependencies[key]]\n",
    "        prune_residual_filter(mod, mod_dep)\n",
    "    i += delta\n",
    "print(get_num_pruned_parameters(parameters_to_prune))\n",
    "print(get_num_parameters(model))\n",
    "# print(validate(val_loader, model))\n",
    "# (30.656659364700317, 3.065665936470032, tensor(0.6995), tensor(0.8420))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_conv_and_bn(conv, bn):\n",
    "    # Fuse Conv2d() and BatchNorm2d() layers https://tehnokv.com/posts/fusing-batchnorm-and-conv/\n",
    "    fusedconv = nn.Conv2d(conv.in_channels,\n",
    "                          conv.out_channels,\n",
    "                          kernel_size=conv.kernel_size,\n",
    "                          stride=conv.stride,\n",
    "                          padding=conv.padding,\n",
    "                          dilation=conv.dilation,\n",
    "                          groups=conv.groups,\n",
    "                          bias=True).requires_grad_(False).to(conv.weight.device)\n",
    "\n",
    "    # Prepare filters\n",
    "    # print(f'before {fusedconv.weight.is_leaf}')\n",
    "    w_conv = conv.weight.clone().view(conv.out_channels, -1)\n",
    "    w_bn = torch.diag(bn.weight.div(torch.sqrt(bn.eps + bn.running_var)))\n",
    "    fusedconv.weight.data = (torch.mm(w_bn, w_conv).view(fusedconv.weight.shape))\n",
    "    # print(f'after {fusedconv.weight.is_leaf}')\n",
    "\n",
    "    # Prepare spatial bias\n",
    "    b_conv = torch.zeros(conv.weight.size(0), device=conv.weight.device) if conv.bias is None else conv.bias\n",
    "    b_bn = bn.bias - bn.weight.mul(bn.running_mean).div(torch.sqrt(bn.running_var + bn.eps))\n",
    "    fusedconv.bias.data = (torch.mm(w_bn, b_conv.reshape(-1, 1)).reshape(-1) + b_bn)\n",
    "    \n",
    "    # Prune fused layer\n",
    "    prune.custom_from_mask(fusedconv, 'weight', mask=conv.weight_mask.data)\n",
    "    bias_mask = getattr(conv, 'bias_mask', torch.ones_like(fusedconv.bias))\n",
    "    prune.custom_from_mask(fusedconv, 'bias', mask=bias_mask)\n",
    "    # prune.remove(fusedconv, 'weight')\n",
    "    # prune.remove(fusedconv, 'bias')\n",
    "\n",
    "    return fusedconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(model.features)):\n",
    "    if isinstance(model.features[i], nn.Conv2d) and isinstance(model.features[i + 1], nn.BatchNorm2d):\n",
    "        model.features[i] = fuse_conv_and_bn(model.features[i], model.features[i + 1])\n",
    "        model.features[i].requires_grad = False\n",
    "        model.features[i + 1] = nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3488)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_pruned_parameters(parameters_to_prune) / get_num_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): Identity()\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): Identity()\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): Identity()\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): Identity()\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): Identity()\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): Identity()\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): Identity()\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (28): Identity()\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): Identity()\n",
       "    (32): ReLU(inplace=True)\n",
       "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (34): Identity()\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (37): Identity()\n",
       "    (38): ReLU(inplace=True)\n",
       "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (41): Identity()\n",
       "    (42): ReLU(inplace=True)\n",
       "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (44): Identity()\n",
       "    (45): ReLU(inplace=True)\n",
       "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (47): Identity()\n",
       "    (48): ReLU(inplace=True)\n",
       "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (50): Identity()\n",
       "    (51): ReLU(inplace=True)\n",
       "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=512, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "# validate(val_loader, model)\n",
    "# (30.52274179458618, 3.0522741794586183, tensor(0.7004), tensor(0.8506))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171.5080738067627"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_s = []\n",
    "for i in range(len(model.features)):\n",
    "    if isinstance(model.features[i], nn.Conv2d):\n",
    "        i_s.append(i)\n",
    "        \n",
    "profiler = Profile()\n",
    "indexing_time = Profile()\n",
    "with profiler:\n",
    "    for i in i_s:\n",
    "        conv = model.features[i]\n",
    "        with indexing_time:\n",
    "            kernel_indices = get_kernel_indices(conv, pruned=False)\n",
    "            filter_indices = get_filter_indices(conv, pruned=False)\n",
    "        \n",
    "        weight = conv.weight.data\n",
    "        bias = conv.bias.data\n",
    "        stride = conv.stride\n",
    "        padding = conv.padding\n",
    "        kernel_size = conv.kernel_size\n",
    "        \n",
    "        model.features[i] = nn.Conv2d(kernel_indices.size()[0], filter_indices.size()[0], kernel_size, stride, padding)\n",
    "        model.features[i].weight.data = weight[filter_indices, :, :, :][:, kernel_indices, :, :]\n",
    "        model.features[i].bias.data = bias[filter_indices]\n",
    "    \n",
    "    # i = i_s[-1]\n",
    "    # conv = model.features[i]\n",
    "    # kernel_indices = get_kernel_indices(conv, pruned=False)\n",
    "    # filter_indices = get_filter_indices(conv, pruned=False)\n",
    "\n",
    "    # weight = conv.weight.data\n",
    "    # bias = conv.bias.data\n",
    "    # stride = conv.stride\n",
    "    # padding = conv.padding\n",
    "    # kernel_size = conv.kernel_size\n",
    "\n",
    "    # model.features[i] = nn.Conv2d(kernel_indices.size()[0], conv.out_channels, kernel_size, stride, padding)\n",
    "    # model.features[i].weight.data = weight[:, kernel_indices, :, :]\n",
    "    # model.features[i].bias.data = bias\n",
    "    \n",
    "    fc = model.classifier[0]\n",
    "    \n",
    "    weight = fc.weight.data\n",
    "    bias = fc.bias.data\n",
    "    out_features = fc.out_features\n",
    "    \n",
    "    model.classifier[0] = nn.Linear(filter_indices.size()[0], fc.out_features, bias=True)\n",
    "    model.classifier[0].weight.data = weight[:, filter_indices]\n",
    "    model.classifier[0].bias.data = bias\n",
    "(profiler.t - indexing_time.t) * 1E3    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(62, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): Identity()\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): Identity()\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): Identity()\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): Identity()\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): Identity()\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): Identity()\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): Identity()\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (28): Identity()\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): Identity()\n",
       "    (32): ReLU(inplace=True)\n",
       "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (34): Identity()\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): Conv2d(512, 443, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (37): Identity()\n",
       "    (38): ReLU(inplace=True)\n",
       "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (40): Conv2d(443, 277, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (41): Identity()\n",
       "    (42): ReLU(inplace=True)\n",
       "    (43): Conv2d(277, 258, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (44): Identity()\n",
       "    (45): ReLU(inplace=True)\n",
       "    (46): Conv2d(258, 133, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (47): Identity()\n",
       "    (48): ReLU(inplace=True)\n",
       "    (49): Conv2d(133, 429, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (50): Identity()\n",
       "    (51): ReLU(inplace=True)\n",
       "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=429, out_features=512, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=512, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "features = nn.Sequential()\n",
    "for name, module in model.features.named_modules():\n",
    "    if isinstance(module, nn.Conv2d) or isinstance(module, nn.MaxPool2d) or isinstance(module, nn.ReLU):\n",
    "        features.add_module(name, copy.deepcopy(module))\n",
    "        \n",
    "classifier = copy.deepcopy(model.classifier)\n",
    "\n",
    "new_model = nn.Sequential(features, nn.Flatten(), classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(62, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (32): ReLU(inplace=True)\n",
       "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): Conv2d(512, 443, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (38): ReLU(inplace=True)\n",
       "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (40): Conv2d(443, 277, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (42): ReLU(inplace=True)\n",
       "    (43): Conv2d(277, 258, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (45): ReLU(inplace=True)\n",
       "    (46): Conv2d(258, 133, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (48): ReLU(inplace=True)\n",
       "    (49): Conv2d(133, 429, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (51): ReLU(inplace=True)\n",
       "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (1): Flatten(start_dim=1, end_dim=-1)\n",
       "  (2): Sequential(\n",
       "    (0): Linear(in_features=429, out_features=512, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=512, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:38<00:00,  1.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(35.002033710479736, 3.5002033710479736, tensor(0.7092), tensor(0.8642))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.eval()\n",
    "validate(val_loader, new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:51] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.rand((1, 3, 32, 32))\n",
    "input_names = ['input']\n",
    "output_names = ['output']\n",
    "onnx_file = f'{model_name}_reduced.onnx'\n",
    "torch.onnx.export(model, dummy_input, onnx_file, input_names=input_names, output_names=output_names,\n",
    "                    dynamic_axes={\n",
    "                        'input': {0: 'batch_size'}\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:45<00:00,  1.14s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(42.48503255844116, 4.248503255844117, tensor(0.7092), tensor(0.8642))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnxruntime as ort \n",
    "onnx_model = ort.InferenceSession(f'{model_name}_reduced.onnx', providers=['CPUExecutionProvider'])\n",
    "validate_onnx(val_loader, onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:47<00:00,  1.19s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(44.22174143791199, 4.4221741437911986, tensor(0.7092), tensor(0.8642))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_model_orig = ort.InferenceSession(f'{model_name}.onnx', providers=['CPUExecutionProvider'])\n",
    "validate_onnx(val_loader, onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:40<00:00,  1.01s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(37.082294940948486, 3.708229494094849, tensor(0.7092), tensor(0.8642))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(val_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:38<00:00,  1.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(35.42549657821655, 3.542549657821655, tensor(0.7043), tensor(0.8642))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_orig = getattr(pytorch_cifar_models, model_name)(pretrained=True)\n",
    "validate(val_loader, model_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate(val_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_total = get_num_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3512970403071919"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0 - (new_total / old_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13371068"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20612004"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
