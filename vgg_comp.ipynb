{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dannya1/anaconda3/envs/torch2/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_cifar_models\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import CIFAR10, CIFAR100\n",
    "from torchmetrics.classification import Accuracy\n",
    "from common import *\n",
    "from collections import OrderedDict\n",
    "# import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 0.005\n",
    "i = 0.005\n",
    "max_sparsity = 0.24\n",
    "mode = 'inf'\n",
    "model_name = 'cifar100_vgg19_bn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f41982c8250>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_val_transforms(mean, std):\n",
    "    return T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean, std)\n",
    "    ])\n",
    "    \n",
    "# CIFAR-10\n",
    "# val_set = CIFAR10('./data', train=False, download=False, transform=get_val_transforms(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]))\n",
    "# train_set = CIFAR10('./data', train=True, download=False)\n",
    "\n",
    "# CIFAR-100\n",
    "val_set = CIFAR100('./data', train=False, download=False, transform=get_val_transforms(mean=[0.5070, 0.4865, 0.4409], std=[0.2673, 0.2564, 0.2761]))\n",
    "train_set = CIFAR100('./data', train=True, download=False)\n",
    "\n",
    "val_loader = data.DataLoader(val_set, batch_size=256, shuffle=False)\n",
    "val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1083.9486122131348"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = Profile()\n",
    "with dt:\n",
    "    model = getattr(pytorch_cifar_models, model_name)(pretrained=True)\n",
    "# model.eval()\n",
    "dt.t * 1E3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (35): ReLU(inplace=True)\n",
      "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (38): ReLU(inplace=True)\n",
      "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (45): ReLU(inplace=True)\n",
      "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (48): ReLU(inplace=True)\n",
      "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (51): ReLU(inplace=True)\n",
      "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=512, out_features=100, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_total = get_num_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity=0.005\n",
      "Sparsity=0.01\n",
      "Sparsity=0.015\n",
      "Sparsity=0.02\n",
      "Sparsity=0.025\n",
      "Sparsity=0.030000000000000002\n",
      "Sparsity=0.035\n",
      "Sparsity=0.04\n",
      "Sparsity=0.045\n",
      "Sparsity=0.049999999999999996\n",
      "Sparsity=0.05499999999999999\n",
      "Sparsity=0.05999999999999999\n",
      "Sparsity=0.06499999999999999\n",
      "Sparsity=0.06999999999999999\n",
      "Sparsity=0.075\n",
      "Sparsity=0.08\n",
      "Sparsity=0.085\n",
      "Sparsity=0.09000000000000001\n",
      "Sparsity=0.09500000000000001\n",
      "Sparsity=0.10000000000000002\n",
      "Sparsity=0.10500000000000002\n",
      "Sparsity=0.11000000000000003\n",
      "Sparsity=0.11500000000000003\n",
      "Sparsity=0.12000000000000004\n",
      "Sparsity=0.12500000000000003\n",
      "Sparsity=0.13000000000000003\n",
      "Sparsity=0.13500000000000004\n",
      "Sparsity=0.14000000000000004\n",
      "Sparsity=0.14500000000000005\n",
      "Sparsity=0.15000000000000005\n",
      "Sparsity=0.15500000000000005\n",
      "Sparsity=0.16000000000000006\n",
      "Sparsity=0.16500000000000006\n",
      "Sparsity=0.17000000000000007\n",
      "Sparsity=0.17500000000000007\n",
      "Sparsity=0.18000000000000008\n",
      "Sparsity=0.18500000000000008\n",
      "Sparsity=0.19000000000000009\n",
      "Sparsity=0.1950000000000001\n",
      "Sparsity=0.2000000000000001\n",
      "Sparsity=0.2050000000000001\n",
      "Sparsity=0.2100000000000001\n",
      "Sparsity=0.2150000000000001\n",
      "Sparsity=0.2200000000000001\n",
      "Sparsity=0.22500000000000012\n",
      "Sparsity=0.23000000000000012\n",
      "Sparsity=0.23500000000000013\n",
      "tensor(7186410)\n",
      "20612004\n"
     ]
    }
   ],
   "source": [
    "dependencies = get_dependency_graph(model, model_name)\n",
    "residual_dependencies = get_residual_dependency(model, model_name)\n",
    "parameters_to_prune = get_parameters_to_prune(model, model_name)\n",
    "name_to_module = get_name_to_module(model)\n",
    "\n",
    "# for mod, param in parameters_to_prune:\n",
    "#     prune.ln_structured(mod, param, 0.2, float('inf'), 0)\n",
    "# for key in dependencies:\n",
    "#     mod = name_to_module[key]\n",
    "#     mod_dep = name_to_module[dependencies[key]]\n",
    "#     prune_kernel2(mod, mod_dep)\n",
    "# for key in residual_dependencies:\n",
    "#     mod = name_to_module[key] \n",
    "#     mod_dep = name_to_module[residual_dependencies[key]]\n",
    "#     prune_residual_filter(mod, mod_dep)\n",
    "\n",
    "# global_smallest_filter(parameters_to_prune, 0.2, mode)\n",
    "while i < max_sparsity:\n",
    "    print(f'Sparsity={i}')\n",
    "    global_smallest_filter(parameters_to_prune, i, mode)\n",
    "    for key in dependencies:\n",
    "        mod = name_to_module[key]\n",
    "        mod_dep = name_to_module[dependencies[key]]\n",
    "        prune_kernel2(mod, mod_dep)\n",
    "    for key in residual_dependencies:\n",
    "        mod = name_to_module[key] \n",
    "        mod_dep = name_to_module[residual_dependencies[key]]\n",
    "        prune_residual_filter(mod, mod_dep)\n",
    "    i += delta\n",
    "print(get_num_pruned_parameters(parameters_to_prune))\n",
    "print(get_num_parameters(model))\n",
    "# print(validate(val_loader, model))\n",
    "# (30.656659364700317, 3.065665936470032, tensor(0.6995), tensor(0.8420))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_conv_and_bn(conv, bn):\n",
    "    # Fuse Conv2d() and BatchNorm2d() layers https://tehnokv.com/posts/fusing-batchnorm-and-conv/\n",
    "    fusedconv = nn.Conv2d(conv.in_channels,\n",
    "                          conv.out_channels,\n",
    "                          kernel_size=conv.kernel_size,\n",
    "                          stride=conv.stride,\n",
    "                          padding=conv.padding,\n",
    "                          dilation=conv.dilation,\n",
    "                          groups=conv.groups,\n",
    "                          bias=True).requires_grad_(False).to(conv.weight.device)\n",
    "\n",
    "    # Prepare filters\n",
    "    # print(f'before {fusedconv.weight.is_leaf}')\n",
    "    w_conv = conv.weight.clone().view(conv.out_channels, -1)\n",
    "    w_bn = torch.diag(bn.weight.div(torch.sqrt(bn.eps + bn.running_var)))\n",
    "    fusedconv.weight.data = (torch.mm(w_bn, w_conv).view(fusedconv.weight.shape))\n",
    "    # print(f'after {fusedconv.weight.is_leaf}')\n",
    "\n",
    "    # Prepare spatial bias\n",
    "    b_conv = torch.zeros(conv.weight.size(0), device=conv.weight.device) if conv.bias is None else conv.bias\n",
    "    b_bn = bn.bias - bn.weight.mul(bn.running_mean).div(torch.sqrt(bn.running_var + bn.eps))\n",
    "    fusedconv.bias.data = (torch.mm(w_bn, b_conv.reshape(-1, 1)).reshape(-1) + b_bn)\n",
    "    \n",
    "    # Prune fused layer\n",
    "    prune.custom_from_mask(fusedconv, 'weight', mask=conv.weight_mask.data)\n",
    "    bias_mask = getattr(conv, 'bias_mask', torch.ones_like(fusedconv.bias))\n",
    "    prune.custom_from_mask(fusedconv, 'bias', mask=bias_mask)\n",
    "    # prune.remove(fusedconv, 'weight')\n",
    "    # prune.remove(fusedconv, 'bias')\n",
    "\n",
    "    return fusedconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(model.features)):\n",
    "    if isinstance(model.features[i], nn.Conv2d) and isinstance(model.features[i + 1], nn.BatchNorm2d):\n",
    "        model.features[i] = fuse_conv_and_bn(model.features[i], model.features[i + 1])\n",
    "        model.features[i].requires_grad = False\n",
    "        model.features[i + 1] = nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3488)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_pruned_parameters(parameters_to_prune) / get_num_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): Identity()\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): Identity()\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): Identity()\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): Identity()\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): Identity()\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): Identity()\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): Identity()\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (28): Identity()\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): Identity()\n",
       "    (32): ReLU(inplace=True)\n",
       "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (34): Identity()\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (37): Identity()\n",
       "    (38): ReLU(inplace=True)\n",
       "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (41): Identity()\n",
       "    (42): ReLU(inplace=True)\n",
       "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (44): Identity()\n",
       "    (45): ReLU(inplace=True)\n",
       "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (47): Identity()\n",
       "    (48): ReLU(inplace=True)\n",
       "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (50): Identity()\n",
       "    (51): ReLU(inplace=True)\n",
       "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=512, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "# validate(val_loader, model)\n",
    "# (30.52274179458618, 3.0522741794586183, tensor(0.7004), tensor(0.8506))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruned architecture\n",
    "pruned_architecture = {}\n",
    "\n",
    "# Original architecture\n",
    "original_architecture = {}\n",
    "\n",
    "# Pruned architecture in tensor format\n",
    "pruned_architecture_pt = torch.tensor([], dtype=torch.int32)\n",
    "\n",
    "# Original architecture in tensor format\n",
    "original_architecture_pt = torch.tensor([], dtype=torch.int32)\n",
    "\n",
    "# Iterate over all conv layers\n",
    "for name, module in model.named_modules():\n",
    "    if not isinstance(module, nn.Conv2d):\n",
    "        continue\n",
    "    \n",
    "    # Get the filter and kernel indices\n",
    "    conv = module\n",
    "    kernel_indices = get_kernel_indices(conv, pruned=False)\n",
    "    filter_indices = get_filter_indices(conv, pruned=False)\n",
    "    \n",
    "    # Get the params\n",
    "    weight = conv.weight.data\n",
    "    bias = conv.bias.data\n",
    "    stride = conv.stride\n",
    "    padding = conv.padding\n",
    "    kernel_size = conv.kernel_size\n",
    "    \n",
    "    # Create the new module\n",
    "    new_mod = nn.Conv2d(kernel_indices.size()[0], filter_indices.size()[0], kernel_size, stride, padding)\n",
    "    new_mod.weight.data = weight[filter_indices, :, :, :][:, kernel_indices, :, :]\n",
    "    new_mod.bias.data = bias[filter_indices]\n",
    "    \n",
    "    # Store the original architecture of the layer\n",
    "    layer = [\n",
    "        f'model.{name}',\n",
    "        module.in_channels,\n",
    "        module.out_channels, \n",
    "        module.kernel_size[0],\n",
    "        module.stride[0],\n",
    "        module.padding[0],\n",
    "        None,\n",
    "        None,\n",
    "    ]\n",
    "    original_architecture[f'model.{name}'] = layer\n",
    "    \n",
    "    # Store the pruned architecture of the layer\n",
    "    layer = [\n",
    "        f'model.{name}',\n",
    "        new_mod.in_channels,\n",
    "        new_mod.out_channels,\n",
    "        new_mod.kernel_size[0],\n",
    "        new_mod.stride[0],\n",
    "        new_mod.padding[0],\n",
    "        filter_indices.tolist(),\n",
    "        kernel_indices.tolist(),                \n",
    "    ]\n",
    "    pruned_architecture[f'model.{name}'] = layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the names list\n",
    "pruned_layer_names = []\n",
    "\n",
    "# Convert to a torch friendly format\n",
    "for i, p in enumerate(list(pruned_architecture.values())):\n",
    "    # Insert the layer name into the names list\n",
    "    pruned_layer_names.append(p[0])\n",
    "    \n",
    "    # Convert layer information into tensor\n",
    "    args = torch.tensor([\n",
    "        i,\n",
    "        p[1], # in_channels\n",
    "        p[2], # out_channels\n",
    "        p[3], # kernel_size\n",
    "        p[4], # stride\n",
    "        p[5], # padding\n",
    "        len(p[6]) if p[6] != None else 0, # Size of kernel indices list\n",
    "        len(p[7]) if p[7]  != None else 0, # Size of filter indices list        \n",
    "    ], dtype=torch.long)\n",
    "    \n",
    "    # Get the filter indices tensor\n",
    "    kernel_indices = torch.tensor(p[6], dtype=torch.long) if p[6] != None else torch.tensor([], dtype=torch.long)\n",
    "    \n",
    "    # Get the kernel indices tensor\n",
    "    filter_indices = torch.tensor(p[7], dtype=torch.long) if p[7] != None else torch.tensor([], dtype=torch.long)\n",
    "    \n",
    "    # Add the layer tensor to the architecture tensor\n",
    "    p_pt = torch.hstack([args, kernel_indices, filter_indices])\n",
    "    pruned_architecture_pt = torch.hstack([pruned_architecture_pt, p_pt])\n",
    "\n",
    "# Initialize the names list\n",
    "original_layer_names = []\n",
    "\n",
    "# Convert to a torch friendly format\n",
    "for i, p in enumerate(list(original_architecture.values())):\n",
    "    # Insert the layer name into the names list\n",
    "    original_layer_names.append(p[0])\n",
    "    \n",
    "    # Convert layer information into tensor\n",
    "    args = torch.tensor([\n",
    "        i,\n",
    "        p[1], # in_channels\n",
    "        p[2], # out_channels\n",
    "        p[3], # kernel_size\n",
    "        p[4], # stride\n",
    "        p[5], # padding\n",
    "        len(p[6]) if p[6] != None else 0, # Size of kernel indices list\n",
    "        len(p[7]) if p[7]  != None else 0, # Size of filter indices list        \n",
    "    ], dtype=torch.long)\n",
    "    \n",
    "    # Get the filter indices tensor\n",
    "    kernel_indices = torch.tensor(p[6], dtype=torch.long) if p[6] != None else torch.tensor([], dtype=torch.long)\n",
    "    \n",
    "    # Get the kernel indices tensor\n",
    "    filter_indices = torch.tensor(p[7], dtype=torch.long) if p[7] != None else torch.tensor([], dtype=torch.long)\n",
    "    \n",
    "    # Add the layer tensor to the architecture tensor\n",
    "    p_pt = torch.hstack([args, kernel_indices, filter_indices])\n",
    "    original_architecture_pt = torch.hstack([original_architecture_pt, p_pt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'data': pruned_architecture_pt,\n",
    "    'names': pruned_layer_names\n",
    "}, f'{model_name}_prun.pt')\n",
    "\n",
    "torch.save({\n",
    "    'data': original_architecture_pt,\n",
    "    'names': original_layer_names\n",
    "}, f'{model_name}_orig.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.02156639099121"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_s = []\n",
    "for i in range(len(model.features)):\n",
    "    if isinstance(model.features[i], nn.Conv2d):\n",
    "        i_s.append(i)\n",
    "        \n",
    "profiler = Profile()\n",
    "indexing_time = Profile()\n",
    "with profiler:\n",
    "    for i in i_s:\n",
    "        conv = model.features[i]\n",
    "        with indexing_time:\n",
    "            kernel_indices = get_kernel_indices(conv, pruned=False)\n",
    "            filter_indices = get_filter_indices(conv, pruned=False)\n",
    "        \n",
    "        weight = conv.weight.data\n",
    "        bias = conv.bias.data\n",
    "        stride = conv.stride\n",
    "        padding = conv.padding\n",
    "        kernel_size = conv.kernel_size\n",
    "        \n",
    "        model.features[i] = nn.Conv2d(kernel_indices.size()[0], filter_indices.size()[0], kernel_size, stride, padding)\n",
    "        model.features[i].weight.data = weight[filter_indices, :, :, :][:, kernel_indices, :, :]\n",
    "        model.features[i].bias.data = bias[filter_indices]\n",
    "    \n",
    "    # i = i_s[-1]\n",
    "    # conv = model.features[i]\n",
    "    # kernel_indices = get_kernel_indices(conv, pruned=False)\n",
    "    # filter_indices = get_filter_indices(conv, pruned=False)\n",
    "\n",
    "    # weight = conv.weight.data\n",
    "    # bias = conv.bias.data\n",
    "    # stride = conv.stride\n",
    "    # padding = conv.padding\n",
    "    # kernel_size = conv.kernel_size\n",
    "\n",
    "    # model.features[i] = nn.Conv2d(kernel_indices.size()[0], conv.out_channels, kernel_size, stride, padding)\n",
    "    # model.features[i].weight.data = weight[:, kernel_indices, :, :]\n",
    "    # model.features[i].bias.data = bias\n",
    "    \n",
    "    fc = model.classifier[0]\n",
    "    \n",
    "    weight = fc.weight.data\n",
    "    bias = fc.bias.data\n",
    "    out_features = fc.out_features\n",
    "    \n",
    "    model.classifier[0] = nn.Linear(filter_indices.size()[0], fc.out_features, bias=True)\n",
    "    model.classifier[0].weight.data = weight[:, filter_indices]\n",
    "    model.classifier[0].bias.data = bias\n",
    "(profiler.t - indexing_time.t) * 1E3    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(51, 102, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): Identity()\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(102, 205, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): Identity()\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): Conv2d(205, 205, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): Identity()\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Conv2d(205, 410, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): Identity()\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(410, 410, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): Identity()\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (22): Conv2d(410, 410, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (23): Identity()\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(410, 410, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): Identity()\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=410, out_features=512, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=512, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = nn.Sequential()\n",
    "for name, module in model.features.named_modules():\n",
    "    if isinstance(module, nn.Conv2d) or isinstance(module, nn.MaxPool2d) or isinstance(module, nn.ReLU):\n",
    "        features.add_module(name, copy.deepcopy(module))\n",
    "        \n",
    "classifier = copy.deepcopy(model.classifier)\n",
    "\n",
    "reduced_model = nn.Sequential(features, nn.Flatten(), classifier)\n",
    "\n",
    "model_orig = getattr(pytorch_cifar_models, model_name)(pretrained=True)\n",
    "fuse_batchnorms(model_orig, model_name, prune_=False)\n",
    "features = nn.Sequential()\n",
    "for name, module in model_orig.features.named_modules():\n",
    "    if isinstance(module, nn.Conv2d) or isinstance(module, nn.MaxPool2d) or isinstance(module, nn.ReLU):\n",
    "        features.add_module(name, copy.deepcopy(module))\n",
    "        \n",
    "classifier = copy.deepcopy(model_orig.classifier)\n",
    "\n",
    "new_model = nn.Sequential(features, nn.Flatten(), classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (1): Flatten(start_dim=1, end_dim=-1)\n",
       "  (2): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=512, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(51, 102, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(102, 205, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): Conv2d(205, 205, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Conv2d(205, 410, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(410, 410, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (22): Conv2d(410, 410, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(410, 410, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (1): Flatten(start_dim=1, end_dim=-1)\n",
       "  (2): Sequential(\n",
       "    (0): Linear(in_features=410, out_features=512, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=512, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:17<00:00,  2.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14.377016067504883, 1.4377016067504882, tensor(0.7078), tensor(0.8887))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(val_loader, new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:16<00:00,  2.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12.876551628112793, 1.2876551628112793, tensor(0.3943), tensor(0.6476))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(val_loader, reduced_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9797092, 6436351)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_parameters(new_model), get_num_parameters(reduced_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:51] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.rand((1, 3, 32, 32))\n",
    "input_names = ['input']\n",
    "output_names = ['output']\n",
    "onnx_file = f'{model_name}_reduced.onnx'\n",
    "torch.onnx.export(reduced_model, dummy_input, onnx_file, input_names=input_names, output_names=output_names,\n",
    "                    dynamic_axes={\n",
    "                        'input': {0: 'batch_size'}\n",
    "                    })\n",
    "\n",
    "dummy_input = torch.rand((1, 3, 32, 32))\n",
    "input_names = ['input']\n",
    "output_names = ['output']\n",
    "onnx_file = f'{model_name}_new.onnx'\n",
    "torch.onnx.export(new_model, dummy_input, onnx_file, input_names=input_names, output_names=output_names,\n",
    "                    dynamic_axes={\n",
    "                        'input': {0: 'batch_size'}\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:22<00:00,  1.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19.49018168449402, 1.949018168449402, tensor(0.7078), tensor(0.8887))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_model_new = ort.InferenceSession(f'{model_name}_new.onnx', providers=['CPUExecutionProvider'])\n",
    "validate_onnx(val_loader, onnx_model_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:25<00:00,  1.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(22.427286624908447, 2.2427286624908445, tensor(0.3943), tensor(0.6476))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_model_reduced = ort.InferenceSession(f'{model_name}_reduced.onnx', providers=['CPUExecutionProvider'])\n",
    "validate_onnx(val_loader, onnx_model_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:16<00:00,  2.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12.925283193588257, 1.2925283193588257, tensor(0.3943), tensor(0.6476))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(val_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:17<00:00,  2.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14.637847423553467, 1.4637847423553467, tensor(0.6564), tensor(0.8347))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_orig = getattr(pytorch_cifar_models, model_name)(pretrained=True)\n",
    "model.eval()\n",
    "validate(val_loader, model_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate(val_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_total = get_num_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34340342088973164"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0 - (new_total / old_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6436351"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9802596"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
